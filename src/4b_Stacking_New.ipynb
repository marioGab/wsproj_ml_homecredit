{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Home Credit Default Risk - Stacking New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# plotting libs\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set() # setting seaborn default for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure size in inches\n",
    "rcParams['figure.figsize'] = 13.5, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path=\"../data/pickles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train = pickle.load(open(os.path.join(data_path, \"prep_train_EF.pkl\"), \"rb\"))\n",
    "prep_test = pickle.load(open(os.path.join(data_path, \"prep_test_EF.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prep_train.shape)\n",
    "print(prep_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SK_IDS = prep_train.SK_ID_CURR\n",
    "X_train = prep_train.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "y_train = prep_train.TARGET\n",
    "\n",
    "X_test_SK_IDS = prep_test.SK_ID_CURR\n",
    "X_test = prep_test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "# Delete \n",
    "del prep_train\n",
    "del prep_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "train_column_names = X_train.columns\n",
    "X_train = pd.DataFrame(std_scaler.transform(X_train), columns=train_column_names)\n",
    "X_test = pd.DataFrame(std_scaler.transform(X_test), columns=train_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Define L1-Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class wrapper for L1-Learners with unique_name property\n",
    "class L1Learner(object):\n",
    "  def __init__(self, clf, unique_name):\n",
    "    self.clf = clf\n",
    "    self.unique_name = unique_name\n",
    "    self.predictions_proba = []\n",
    "    self.predictions = []\n",
    "    self.predictions_proba_test = []\n",
    "  def __repr__(self):\n",
    "    return 'Type:{} | Name: {}'.format(self.clf.__class__.__name__, self.unique_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logreg = L1Learner(LogisticRegression(), unique_name='LogisticRegression')\n",
    "clf_logreg.clf.set_params(**{\n",
    "  'C': 1,\n",
    "  'class_weight': None,\n",
    "  'n_jobs': -1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = L1Learner(RandomForestClassifier(), unique_name='RandomForestClassifier')\n",
    "clf_rf.clf.set_params(**{\n",
    "  'max_leaf_nodes': 70,\n",
    "  'n_estimators': 150,\n",
    "  'n_jobs': -1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_2 = L1Learner(RandomForestClassifier(), unique_name='RandomForestClassifier_2')\n",
    "clf_rf_2.clf.set_params(**{\n",
    "  'n_estimators': 200,\n",
    "  'max_features': 0.2,\n",
    "  'max_depth': 12,\n",
    "  'min_samples_leaf': 2,\n",
    "  'n_jobs': -1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = L1Learner(XGBClassifier(), unique_name='XGBClassifier')\n",
    "clf_xgb.clf.set_params(**{\n",
    "  \"n_estimators\": 1000,\n",
    "  \"max_depth\": 4,\n",
    "  \"min_child_weight\": 4,\n",
    "  \"subsample\": 0.8,\n",
    "  \"learning_rate\": 0.01,\n",
    "  \"colsample_bytree\": 0.8,\n",
    "  \"objective\": 'binary:logistic',\n",
    "  'n_jobs': -1,\n",
    "  \"random_state\": 42\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_2 = L1Learner(XGBClassifier(), unique_name='XGBClassifier_2')\n",
    "clf_xgb_2.clf.set_params(**{\n",
    "  'colsample_bytree': 0.7,\n",
    "  'silent': 1,\n",
    "  'subsample': 0.7,\n",
    "  'learning_rate': 0.075,\n",
    "  'objective': 'binary:logistic',\n",
    "  'max_depth': 4,\n",
    "  'min_child_weight': 1,\n",
    "  'n_jobs': -1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_3 = L1Learner(XGBClassifier(), unique_name='XGBClassifier_MB')\n",
    "clf_xgb_3.clf.set_params(**{\n",
    "  'max_depth': 6,\n",
    "  'subsample': 0.8,\n",
    "  'colsample_bytree': 0.632,\n",
    "  'min_child_weight': 35,\n",
    "  'objective': 'binary:logistic',\n",
    "  'silent': 1,\n",
    "  'n_jobs': -1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgm = L1Learner(LGBMClassifier(), unique_name='LightGBM')\n",
    "clf_lgm.clf.set_params(**{\n",
    "  'n_estimators': 10000,\n",
    "  'learning_rate': 0.02,\n",
    "  'num_leaves': 34,\n",
    "  'colsample_bytree': 0.9497036,\n",
    "  'subsample': 0.8715623,\n",
    "  'max_depth': 8,\n",
    "  'reg_alpha':0.041545473,\n",
    "  'reg_lambda':0.0735294,\n",
    "  'min_split_gain': 0.0222415,\n",
    "  'min_child_weight': 39.3259775,\n",
    "  'n_jobs': -1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgm_2 = L1Learner(LGBMClassifier(), unique_name='LightGBM_2')\n",
    "clf_lgm_2.clf.set_params(**{\n",
    "  'n_estimators':200,\n",
    "  'learning_rate':0.1,\n",
    "  'num_leaves':123,\n",
    "  'colsample_bytree':0.8,\n",
    "  'subsample':0.9,\n",
    "  'max_depth':15,\n",
    "  'reg_alpha':0.1,\n",
    "  'reg_lambda':0.1,\n",
    "  'min_split_gain':0.01,\n",
    "  'min_child_weight':2,\n",
    "  'n_jobs': -1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sgd = L1Learner(SGDClassifier(), unique_name='SGDClassifier')\n",
    "clf_sgd.clf.set_params(**{\n",
    "  'n_iter': 1, \n",
    "  'warm_start': True, \n",
    "  'penalty':'l2', \n",
    "  'loss': 'log', \n",
    "  'learning_rate': 'constant', \n",
    "  'eta0': 0.0005, \n",
    "  'n_jobs':-1,\n",
    "  'random_state':42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_etc = L1Learner(ExtraTreesClassifier(), unique_name='ExtraTreesClassifier')\n",
    "clf_etc.clf.set_params(**{\n",
    "  'n_estimators': 200,\n",
    "  'max_features': 0.5,\n",
    "  'max_depth': 12,\n",
    "  'min_samples_leaf': 2,\n",
    "  'n_jobs':-1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cat = L1Learner(CatBoostClassifier(), unique_name='CatBoosClassifier')\n",
    "clf_cat.clf.set_params(**{\n",
    "  'iterations': 200,\n",
    "  'learning_rate': 0.5,\n",
    "  'depth': 3,\n",
    "  'l2_leaf_reg': 40,\n",
    "  'bootstrap_type': 'Bernoulli',\n",
    "  'subsample': 0.7,\n",
    "  'scale_pos_weight': 5,\n",
    "  'eval_metric': 'AUC',\n",
    "  'od_type': 'Iter',\n",
    "  'allow_writing_files': False,\n",
    "  #'n_jobs':-1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp = L1Learner(MLPClassifier(), unique_name='MLPClassifier')\n",
    "clf_mlp.clf.set_params(**{\n",
    "  'alpha': 0.20842163497959337, \n",
    "  'hidden_layer_sizes': (70, 30),\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Train L1-Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define L1-Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_learners = []\n",
    "#l1_learners.append(clf_logreg)\n",
    "#l1_learners.append(clf_rf)\n",
    "#l1_learners.append(clf_rf_2)\n",
    "#l1_learners.append(clf_xgb)\n",
    "#l1_learners.append(clf_xgb_2)\n",
    "#l1_learners.append(clf_xgb_3)\n",
    "#l1_learners.append(clf_lgm)\n",
    "#l1_learners.append(clf_lgm_2)\n",
    "#l1_learners.append(clf_sgd)\n",
    "#l1_learners.append(clf_etc)\n",
    "#l1_learners.append(clf_cat)\n",
    "#l1_learners.append(clf_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from os import listdir\n",
    "\n",
    "def train_l1_learners(skf, l1_learners, X_tr, y_tr, X_te):\n",
    "  \n",
    "  print(\"Number of Learners to train: {}\".format(len(l1_learners)))\n",
    "  \n",
    "  for learner in l1_learners:\n",
    "    \n",
    "    learner.predictions = np.zeros((X_tr.shape[0], 1))\n",
    "    learner.predictions_proba = np.zeros((X_tr.shape[0], 1))\n",
    "    learner.predictions_proba_test = np.zeros((X_te.shape[0], skf.n_splits))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print('Start training {}'.format(learner))\n",
    "    \n",
    "    fold = 0\n",
    "    for train_idx, test_idx in skf.split(X_tr, y_tr):\n",
    "      print('Fold #{}'.format(fold))\n",
    "      # split data for cv\n",
    "      X_train_cv = X_train.iloc[train_idx, :]\n",
    "      y_train_cv = y_train.iloc[train_idx]\n",
    "      X_test_cv  = X_train.iloc[test_idx, :]\n",
    "      y_test_cv  = y_train.iloc[test_idx]\n",
    "      \n",
    "      # train clf\n",
    "      learner.clf.fit(X_train_cv, y_train_cv)\n",
    "      \n",
    "      # make predictions on X_pred\n",
    "      learner.predictions[test_idx, 0] = learner.clf.predict(X_test_cv)\n",
    "      learner.predictions_proba[test_idx, 0] = learner.clf.predict_proba(X_test_cv)[:, 1]\n",
    "      \n",
    "      # make predictions for X_test\n",
    "      learner.predictions_proba_test[:, fold] = learner.clf.predict_proba(X_te)[:, 1]\n",
    "      \n",
    "      # print score\n",
    "      score = roc_auc_score(y_test_cv, learner.predictions_proba[test_idx, 0])\n",
    "      print(\"Score on X_pred for fold {} (ROC AUC): {}\".format(fold, score))\n",
    "      fold += 1\n",
    "      \n",
    "    end_time = time.time()\n",
    "    print(\"End (Elapsed time is {} min.)\".format((end_time - start_time) / 60))\n",
    "    print(40*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# define StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "train_l1_learners(skf, l1_learners, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load models and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "stacking_models_dir = './stacking_models'\n",
    "\n",
    "stacking_model_prefix = 'stacking_CV_'\n",
    "#stacking_model_prefix = 'stacking_60_'\n",
    "#stacking_model_prefix = 'stacking_75_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load learners\n",
    "l1_learners = []\n",
    "\n",
    "for f in os.listdir(stacking_models_dir):\n",
    "  if f.startswith(stacking_model_prefix):\n",
    "    l1_learners.append(joblib.load(\"{}/{}\".format(stacking_models_dir, f)))\n",
    "    \n",
    "l1_learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save learners\n",
    "for learner in l1_learners:\n",
    "  joblib.dump(learner, '{}/{}{}.pkl'.format(stacking_models_dir, stacking_model_prefix, learner.unique_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create new dataset with L1-Learners predictions + extra features\n",
    "\n",
    "Add these features to the l1 predictions for training meta classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features = ['AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "                  'DAYS_EMPLOYED_PERC', 'INCOME_CREDIT_PERC', 'INCOME_PER_PERSON', 'ANNUITY_INCOME_PERC', \n",
    "                  'PAYMENT_RATE', 'EXT_SOURCES_MEAN', 'EXT_SOURCES_PRODUCT', 'NEW_PHONE_TO_BIRTH_RATIO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', \n",
    "                 'INCOME_CREDIT_PERC', 'INCOME_PER_PERSON', 'ANNUITY_INCOME_PERC', 'PAYMENT_RATE', 'DAYS_BIRTH', 'DAYS_EMPLOYED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler for meta featuers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def create_meta_dataset(learners, extra_features, scaling=False, add_mean_as_feature=False):\n",
    "  \n",
    "  X_train_meta = pd.DataFrame()\n",
    "  X_test_meta = pd.DataFrame()\n",
    "  \n",
    "  for learner in learners:\n",
    "    clf_name = learner.unique_name\n",
    "    # each column in train_meta is the pred_proba of a L1-Learner\n",
    "    X_train_meta[clf_name] = learner.predictions_proba[:, 0]\n",
    "    \n",
    "    # test_meta is the mean of the n-fold predictions on test dataset (stil unseen)\n",
    "    X_test_meta[clf_name] = learner.predictions_proba_test.mean(1)\n",
    "  \n",
    "  if add_mean_as_feature:\n",
    "    X_train_meta['Clf_Mean'] = X_train_meta.mean(axis=1)\n",
    "    X_test_meta['Clf_mean'] = X_test_meta.mean(axis=1)\n",
    "    \n",
    "  # Add extra features\n",
    "  if len(extra_features) > 0:\n",
    "    for col in extra_features:\n",
    "      # get index of the column\n",
    "      idx = np.where(X_train.columns.values == col)[0][0]\n",
    "      X_train_meta[col] = X_train.iloc[:,idx]\n",
    "      idx = np.where(X_test.columns.values == col)[0][0]\n",
    "      X_test_meta[col] = X_test.iloc[:,idx]\n",
    "      \n",
    "  # Scale data\n",
    "  if scaling:\n",
    "    scaler_meta = StandardScaler()\n",
    "    scaler_meta.fit(X_train_meta)\n",
    "    X_train_meta = pd.DataFrame(scaler_meta.transform(X_train_meta), columns=X_train_meta.columns)\n",
    "    X_test_meta = pd.DataFrame(scaler_meta.transform(X_test_meta), columns=X_test_meta.columns)\n",
    "    \n",
    "  return X_train_meta, X_test_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta, X_test_meta = create_meta_dataset(l1_learners, extra_features, scaling=True, add_mean_as_feature=False)\n",
    "print(X_train_meta.shape)\n",
    "print(X_test_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train meta classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_scores(grid_cv):\n",
    "  print(\"Best Score: {}\".format(grid_cv.best_score_))\n",
    "  print(\"Best Params: {}\".format(grid_cv.best_params_))\n",
    "  for mean, std, params in zip(grid_cv.cv_results_['mean_test_score'], grid_cv.cv_results_['std_test_score'], grid_cv.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_sgd = SGDClassifier()\n",
    "\n",
    "clf_meta_grid_sgd = {\n",
    "  \"loss\": Categorical(['log','modified_huber']),\n",
    "  \"penalty\": Categorical(['l1', 'l2', 'elasticnet']),\n",
    "  \"l1_ratio\": Real(0.00000001, 1, prior='log-uniform'),\n",
    "  \"alpha\": Real(0.001, 10, prior='log-uniform'),\n",
    "  'tol': Real(0.00001, 3, prior='log-uniform'),\n",
    "  #\"class_weight\": Categorical([None]),\n",
    "  #'learning_rate': Categorical(['optimal']),\n",
    "  #'eta0': Integer(0.1, 1),\n",
    "#  'max_iter': Integer(5, 500)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_sgd = BayesSearchCV(clf_meta_sgd, search_spaces=clf_meta_grid_sgd, cv=5, n_jobs=-1, \n",
    "                                verbose=3, scoring='roc_auc', n_iter=70, random_state=42)\n",
    "gridcv_meta_sgd.fit(X_train_meta, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gridcv_meta_sgd, '{}/{}{}.pkl'.format(stacking_models_dir, 'meta_', 'sgd_with_domainfeatures'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_logreg = LogisticRegression()\n",
    "clf_meta_grid_logreg = [\n",
    "  {\n",
    "    'C': Real(0.00001, 100, prior='log-uniform'),\n",
    "    'tol': Real(0.00004, 1, prior='log-uniform'),\n",
    "    'penalty': Categorical(['l1', 'l2']),\n",
    "    'random_state': [42],\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_logreg = BayesSearchCV(clf_meta_logreg, search_spaces=clf_meta_grid_logreg, \n",
    "                                   cv=5, n_jobs=-1, verbose=3, scoring='roc_auc', n_iter=50)\n",
    "gridcv_meta_logreg.fit(X_train_meta, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gridcv_meta_logreg, '{}/{}{}.pkl'.format(stacking_models_dir, 'meta_', 'logreg_with_domainfeatures'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_svc = SVC()\n",
    "clf_meta_grid_svc = [\n",
    "  {\n",
    "    'C': [1], #, 0.1, 1],\n",
    "    'kernel': ['linear'],\n",
    "#    'gamma': [0.01, 1.0],\n",
    "    'class_weight': ['balanced'],\n",
    "    'random_state': [42],\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_svc = GridSearchCV(clf_meta_svc, clf_meta_grid_svc, cv=5, n_jobs=5, verbose=3, scoring='roc_auc')\n",
    "gridcv_meta_svc.fit(X_train_meta, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf_meta_xgb = XGBClassifier()\n",
    "\n",
    "#clf_meta_grid_xgb = {\n",
    "#  \"n_estimators\": [25, 100, 250, 300],\n",
    "#  \"max_depth\": [4, 8 , 16],\n",
    "#  \"num_leaves\": [15, 30]\n",
    "#  \"min_child_weight\": [4, 8],\n",
    "#  \"subsample\": [0.2, 0.8],\n",
    "#  \"learning_rate\": [0.01],\n",
    "#  \"colsample_bytree\": [0.8, 0.6],\n",
    "#  \"objective\": ['binary:logistic'],\n",
    "#  \"random_state\": [42]\n",
    "#}\n",
    "\n",
    "# best params\n",
    "clf_meta_grid_xgb = {\n",
    "  \"n_estimators\": [200, 300],\n",
    "  \"max_depth\": [4],\n",
    "  \"min_child_weight\": [8],\n",
    "  \"subsample\": [0.2],\n",
    "  \"learning_rate\": [0.01],\n",
    "  \"colsample_bytree\": [0.8],\n",
    "  \"objective\": ['binary:logistic'],\n",
    "  \"random_state\": [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_gdb = GridSearchCV(clf_meta_xgb, param_grid=clf_meta_grid_xgb, cv=5, n_jobs=-1, verbose=5, scoring='roc_auc')\n",
    "gridcv_meta_gdb.fit(X_train_meta, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_gdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf_meta_xgb = XGBClassifier(objective='binary:logistic', eval_metric='auc')\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "  clf_meta_xgb, \n",
    "  search_spaces=\n",
    "  {\n",
    "    \"n_estimators\": Integer(50, 250),\n",
    "    \"max_depth\": Integer(1, 35),\n",
    "    \"min_child_weight\": Integer(1, 100),\n",
    "    \"subsample\": Real(0.1, 0.9, prior='log-uniform'),\n",
    "    \"learning_rate\": Real(0.001, 0.1, prior='log-uniform'),\n",
    "    \"colsample_bytree\": Real(0.1, 0.9, prior='log-uniform')\n",
    "  },\n",
    "  n_iter=15,\n",
    "  random_state=42,\n",
    "  verbose=3,\n",
    "  scoring = 'roc_auc',\n",
    "  cv=5,\n",
    "  n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train_meta, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_lgm = LGBMClassifier()\n",
    "\n",
    "clf_meta_grid_lgm = {\n",
    "  'n_estimators': [250, 280, 290, 300],\n",
    "  'learning_rate': [0.02, 0.001],\n",
    "  'num_leaves': [25, 30],\n",
    "  'max_depth': [16, 20, 25],\n",
    "  'random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_lgm = GridSearchCV(clf_meta_lgm, param_grid=clf_meta_grid_lgm, cv=5, n_jobs=-1, verbose=5, scoring='roc_auc')\n",
    "gridcv_meta_lgm.fit(X_train_meta, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_lgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiLayer-Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_mlp = MLPClassifier()\n",
    "\n",
    "clf_meta_grid_mlp = {\n",
    "  #'hidden_layer_sizes': Categorical([(8,5)]),\n",
    "  'hidden_layer_sizes': Categorical([(3,), (5,), (10,), (8,2)]),\n",
    "  'activation': Categorical(['relu', 'logistic', 'tanh']),\n",
    "  'epsilon': Real(1e-9, 1e-4, prior='log-uniform'),\n",
    "  'alpha': Real(0.000000001, 2, prior='log-uniform'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_mlp = BayesSearchCV(clf_meta_mlp, search_spaces=clf_meta_grid_mlp, cv=5, n_jobs=-1, \n",
    "                                verbose=5, random_state=49, scoring='roc_auc', n_iter=70)\n",
    "gridcv_meta_mlp.fit(X_train_meta, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gridcv_meta_mlp, '{}/{}{}.pkl'.format(stacking_models_dir, 'meta_', 'mlp_without_domainfeatures'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Predictions of L1-Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X_test_meta.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediciton for train set and submit csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_clf = gridcv_meta_logreg.best_estimator_\n",
    "#meta_clf = gridcv_meta_gdb.best_estimator_\n",
    "#meta_clf = gridcv_meta_lgm.best_estimator_\n",
    "#meta_clf = opt.best_estimator_\n",
    "#meta_clf = gridcv_meta_sgd.best_estimator_\n",
    "meta_clf = gridcv_meta_mlp.best_estimator_\n",
    "\n",
    "y_test = meta_clf.predict_proba(X_test_meta)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_clf = gridcv_meta_sgd___.best_estimator_\n",
    "#meta_clf = gridcv_meta_sgd_df.best_estimator_\n",
    "\n",
    "#meta_clf = gridcv_meta_logreg___.best_estimator_\n",
    "#meta_clf = gridcv_meta_logreg_df.best_estimator_\n",
    "\n",
    "#meta_clf = gridcv_meta_mlp___.best_estimator_\n",
    "meta_clf = gridcv_meta_mlp_df.best_estimator_\n",
    "\n",
    "y_test = meta_clf.predict_proba(X_test_meta)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear stretch of predictions to [0,1]\n",
    "y_test = (y_test - y_test.min()) / (y_test.max() - y_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the submission dataframe\n",
    "submission = pd.DataFrame({'SK_ID_CURR': X_test_SK_IDS, 'TARGET': y_test})\n",
    "submission = submission.sort_values(by='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./stacking_submissions/meta_paper/meta_mlp_2_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Grids \n",
    "gridcv_meta_sgd___ = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_sgd_without_domainfeatures'))\n",
    "gridcv_meta_sgd_df = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_sgd_with_domainfeatures'))\n",
    "\n",
    "gridcv_meta_logreg___ = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_logreg_without_domainfeatures'))\n",
    "gridcv_meta_logreg_df = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_logreg_with_domainfeatures'))\n",
    "\n",
    "gridcv_meta_mlp___ = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_mlp_without_domainfeatures'))\n",
    "gridcv_meta_mlp_df = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_mlp_with_domainfeatures'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD (no domain features)\n",
    "sgd_scores_no_domain = cross_val_predict(gridcv_meta_sgd___.best_estimator_, X_train_meta, y_train, cv=5, n_jobs=-1, method='predict_proba')\n",
    "#sgd_scores_with_domain = cross_val_predict(gridcv_meta_sgd_df.best_estimator_, X_train_meta, y_train, cv=5, n_jobs=-1, method='predict_proba')\n",
    "\n",
    "logreg_scores_no_domain = cross_val_predict(gridcv_meta_logreg___.best_estimator_, X_train_meta, y_train, cv=5, n_jobs=-1, method='predict_proba')\n",
    "#logreg_scores_with_domain = cross_val_predict(gridcv_meta_logreg_df.best_estimator_, X_train_meta, y_train, cv=5, n_jobs=-1, method='predict_proba')\n",
    "\n",
    "mlp_scores_no_domain = cross_val_predict(gridcv_meta_mlp___.best_estimator_, X_train_meta, y_train, cv=5, n_jobs=-1, method='predict_proba')\n",
    "#mlp_scores_with_domain = cross_val_predict(gridcv_meta_mlp_df.best_estimator_, X_train_meta, y_train, cv=5, n_jobs=-1, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('ROC Meta-Learners with Stacking (Method B)')\n",
    "\n",
    "# SGD (no domain)\n",
    "fpr, tpr, threshold = roc_curve(y_train, sgd_scores_no_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='SGD (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.76003, 0.75919))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, sgd_scores_with_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='SGD with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75966, 0.75941))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, logreg_scores_no_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='LogReg (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75677, 0.75612))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, logreg_scores_with_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='LogReg with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75947, 0.75856))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, mlp_scores_no_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='NN (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75891, 0.75935))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, mlp_scores_with_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='NN with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.76090, 0.76064))\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD (no domain)\n",
    "fpr, tpr, threshold = roc_curve(y_train, sgd_scores_no_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='SGD (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.76003, 0.75919))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, sgd_scores_with_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='SGD with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75966, 0.75941))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, logreg_scores_no_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='LogReg (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75677, 0.75612))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, logreg_scores_with_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='LogReg with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75947, 0.75856))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, mlp_scores_no_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='MLP (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75891, 0.75935))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, mlp_scores_with_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='MLP with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.76090, 0.76064))\n",
    "\n",
    "plt.grid()\n",
    "plt.title('ROC Meta-Learners with Stacking (Method B)', fontsize=14)\n",
    "plt.xlabel('False positive rate', fontsize=14)\n",
    "plt.ylabel('True positive rate', fontsize=14)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 14})\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
