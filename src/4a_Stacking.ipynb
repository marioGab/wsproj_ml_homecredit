{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Home Credit Default Risk - Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting libs\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "#sns.set() # setting seaborn default for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure size in inches\n",
    "rcParams['figure.figsize'] = 13.5, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path=\"../data/pickles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train = pickle.load(open(os.path.join(data_path, \"prep_train_EF.pkl\"), \"rb\"))\n",
    "prep_test = pickle.load(open(os.path.join(data_path, \"prep_test_EF.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prep_train.shape)\n",
    "print(prep_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SK_IDS = prep_train.SK_ID_CURR\n",
    "X_train = prep_train.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "y_train = prep_train.TARGET\n",
    "\n",
    "X_test_SK_IDS = prep_test.SK_ID_CURR\n",
    "X_test = prep_test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "# Delete \n",
    "#del prep_train\n",
    "#del prep_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = std_scaler.transform(X_train)\n",
    "X_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split prep_train into X_train_base and X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base, X_pred_base, y_train_base, y_pred_base = train_test_split(X_train, y_train, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Define L1-Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class wrapper for L1-Learners with unique_name property\n",
    "class L1Learner(object):\n",
    "  def __init__(self, clf, unique_name):\n",
    "    self.clf = clf\n",
    "    self.unique_name = unique_name\n",
    "    self.predictions_proba = []\n",
    "    self.predictions = []\n",
    "  def __repr__(self):\n",
    "    return 'Type:{} | Name: {}'.format(self.clf.__class__.__name__, self.unique_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logreg = L1Learner(LogisticRegression(), unique_name='LogisticRegression')\n",
    "clf_logreg.clf.set_params(**{\n",
    "  'C': 1,\n",
    "  'class_weight': 'balanced',\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = L1Learner(RandomForestClassifier(), unique_name='RandomForestClassifier')\n",
    "clf_rf.clf.set_params(**{\n",
    "  'max_leaf_nodes': 70,\n",
    "  'n_estimators': 150,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_2 = L1Learner(RandomForestClassifier(), unique_name='RandomForestClassifier_2')\n",
    "clf_rf_2.clf.set_params(**{\n",
    "  'n_estimators': 200,\n",
    "  'max_features': 0.2,\n",
    "  'max_depth': 12,\n",
    "  'min_samples_leaf': 2,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = L1Learner(XGBClassifier(), unique_name='XGBClassifier')\n",
    "clf_xgb.clf.set_params(**{\n",
    "  \"n_estimators\": 1000,\n",
    "  \"max_depth\": 4,\n",
    "  \"min_child_weight\": 4,\n",
    "  \"subsample\": 0.8,\n",
    "  \"learning_rate\": 0.01,\n",
    "  \"colsample_bytree\": 0.8,\n",
    "  \"objective\": 'binary:logistic',\n",
    "  \"random_state\": 42\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_2 = L1Learner(XGBClassifier(), unique_name='XGBClassifier_2')\n",
    "clf_xgb_2.clf.set_params(**{\n",
    "  'colsample_bytree': 0.7,\n",
    "  'silent': 1,\n",
    "  'subsample': 0.7,\n",
    "  'learning_rate': 0.075,\n",
    "  'objective': 'binary:logistic',\n",
    "  'max_depth': 4,\n",
    "  'min_child_weight': 1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgm = L1Learner(LGBMClassifier(), unique_name='LightGBM')\n",
    "clf_lgm.clf.set_params(**{\n",
    "  'n_estimators': 10000,\n",
    "  'learning_rate': 0.02,\n",
    "  'num_leaves': 34,\n",
    "  'colsample_bytree': 0.9497036,\n",
    "  'subsample': 0.8715623,\n",
    "  'max_depth': 8,\n",
    "  'reg_alpha':0.041545473,\n",
    "  'reg_lambda':0.0735294,\n",
    "  'min_split_gain': 0.0222415,\n",
    "  'min_child_weight': 39.3259775\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgm_2 = L1Learner(LGBMClassifier(), unique_name='LightGBM_2')\n",
    "clf_lgm_2.clf.set_params(**{\n",
    "  'n_estimators':200,\n",
    "  'learning_rate':0.1,\n",
    "  'num_leaves':123,\n",
    "  'colsample_bytree':0.8,\n",
    "  'subsample':0.9,\n",
    "  'max_depth':15,\n",
    "  'reg_alpha':0.1,\n",
    "  'reg_lambda':0.1,\n",
    "  'min_split_gain':0.01,\n",
    "  'min_child_weight':2,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sgd = L1Learner(SGDClassifier(), unique_name='SGDClassifier')\n",
    "clf_sgd.clf.set_params(**{\n",
    "  'n_iter': 1, \n",
    "  'warm_start': True, \n",
    "  'penalty':'l2', \n",
    "  'loss': 'log', \n",
    "  'learning_rate': 'constant', \n",
    "  'eta0': 0.0005, \n",
    "  'random_state':42, \n",
    "  'n_jobs':4\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_etc = L1Learner(ExtraTreesClassifier(), unique_name='ExtraTreesClassifier')\n",
    "clf_etc.clf.set_params(**{\n",
    "  'n_jobs': -1,\n",
    "  'n_estimators': 200,\n",
    "  'max_features': 0.5,\n",
    "  'max_depth': 12,\n",
    "  'min_samples_leaf': 2,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cat = L1Learner(CatBoostClassifier(), unique_name='CatBoosClassifier')\n",
    "clf_cat.clf.set_params(**{\n",
    "  'iterations': 200,\n",
    "  'learning_rate': 0.5,\n",
    "  'depth': 3,\n",
    "  'l2_leaf_reg': 40,\n",
    "  'bootstrap_type': 'Bernoulli',\n",
    "  'subsample': 0.7,\n",
    "  'scale_pos_weight': 5,\n",
    "  'eval_metric': 'AUC',\n",
    "  'od_type': 'Iter',\n",
    "  'allow_writing_files': False,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp = L1Learner(MLPClassifier(), unique_name='MLPClassifier')\n",
    "clf_mlp.clf.set_params(**{\n",
    "  'alpha': 0.1,\n",
    "  'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Train L1-Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_learners = []\n",
    "l1_learners.append(clf_logreg)\n",
    "l1_learners.append(clf_rf)\n",
    "l1_learners.append(clf_rf_2)\n",
    "l1_learners.append(clf_xgb)\n",
    "l1_learners.append(clf_xgb_2)\n",
    "l1_learners.append(clf_lgm)\n",
    "l1_learners.append(clf_lgm_2)\n",
    "l1_learners.append(clf_sgd)\n",
    "l1_learners.append(clf_etc)\n",
    "l1_learners.append(clf_cat)\n",
    "l1_learners.append(clf_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_l1_learners(l1_learners, X_t, y_t, X_p, y_p):\n",
    "  print(\"Number of Learners to train: {}\".format(len(l1_learners)))\n",
    "  for learner in l1_learners:\n",
    "    # train clf\n",
    "    start_time = time.time()\n",
    "    print('Training {}'.format(learner))\n",
    "    learner.clf.fit(X_t, y_t)\n",
    "    \n",
    "    # make predictions on X_pred\n",
    "    learner.predictions = learner.clf.predict(X_p)\n",
    "    learner.predictions_proba = learner.clf.predict_proba(X_p)\n",
    "    # print score\n",
    "    score = roc_auc_score(y_p, learner.predictions_proba[:,1])\n",
    "    print(\"Score on X_pred (ROC AUC): {}\".format(score))\n",
    "    end_time = time.time()\n",
    "    print(\"End (Elapsed time is {} min.)\".format((end_time - start_time) / 60))\n",
    "    print(40*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l1_learners(l1_learners, X_train_base, y_train_base, X_pred_base, y_pred_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load models and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "stacking_models_dir = './stacking_models'\n",
    "\n",
    "stacking_model_prefix = 'stacking_60_'\n",
    "#stacking_model_prefix = 'stacking_75_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load learners\n",
    "l1_learners = []\n",
    "\n",
    "for f in os.listdir(stacking_models_dir):\n",
    "  if f.startswith(stacking_model_prefix):\n",
    "    l1_learners.append(joblib.load(\"{}/{}\".format(stacking_models_dir, f)))\n",
    "\n",
    "l1_learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save learners\n",
    "for learner in l1_learners:\n",
    "  joblib.dump(learner, '{}/{}{}.pkl'.format(stacking_models_dir, stacking_model_prefix, learner.unique_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def print_l1_learners_rocauc(l1_learners, y_p):\n",
    "  for learner in l1_learners:\n",
    "    print('CLF: {}'.format(learner))\n",
    "    \n",
    "    # print score\n",
    "    score = roc_auc_score(y_p, learner.predictions_proba[:,1])\n",
    "    print(\"Score on X_pred (ROC AUC): {}\".format(score))\n",
    "    print(40*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_l1_learners_rocauc(l1_learners, y_pred_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create new dataset with L1-Learners predictions + extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler for meta featuers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_meta = StandardScaler()\n",
    "#scaler_meta = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these features to the l1 predictions for training meta classifier\n",
    "extra_features = ['AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "                  'DAYS_EMPLOYED_PERC', 'INCOME_CREDIT_PERC', 'INCOME_PER_PERSON', 'ANNUITY_INCOME_PERC', \n",
    "                  'PAYMENT_RATE', 'EXT_SOURCES_MEAN', 'EXT_SOURCES_PRODUCT', 'NEW_PHONE_TO_BIRTH_RATIO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', \n",
    "                 'INCOME_CREDIT_PERC', 'INCOME_PER_PERSON', 'ANNUITY_INCOME_PERC', 'PAYMENT_RATE', 'DAYS_BIRTH', 'DAYS_EMPLOYED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_meta_dataset(learners, X, extra_features, scaler_meta=None):\n",
    "  X_train_meta = pd.DataFrame()\n",
    "  for learner in learners:\n",
    "    clf_name = learner.unique_name\n",
    "    X_train_meta[clf_name] = learner.predictions_proba[:, 1]\n",
    "    #X_train_meta[clf_name] = learner.predictions[:, 1]\n",
    "    \n",
    "  # Add extra features\n",
    "  if len(extra_features) > 0:\n",
    "    columns = prep_train.columns[2:]\n",
    "    for col in extra_features:\n",
    "      # get index of the column\n",
    "      idx = np.where(prep_train.columns[2:].values == col)[0][0]\n",
    "      X_train_meta[col] = X[:,idx]\n",
    "      \n",
    "  # save column names \n",
    "  columns = X_train_meta.columns\n",
    "  \n",
    "  # Scale data\n",
    "  if scaler_meta:\n",
    "    scaler_meta.fit(X_train_meta)\n",
    "    X_train_meta = pd.DataFrame(scaler_meta.transform(X_train_meta), columns=columns)\n",
    "    \n",
    "  return X_train_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta = create_meta_dataset(l1_learners, X_pred_base, extra_features, scaler_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train meta classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_scores(grid_cv):\n",
    "  print(\"Best Score: {}\".format(grid_cv.best_score_))\n",
    "  print(\"Best Params: {}\".format(grid_cv.best_params_))\n",
    "  for mean, std, params in zip(grid_cv.cv_results_['mean_test_score'], grid_cv.cv_results_['std_test_score'], grid_cv.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_sgd = SGDClassifier()\n",
    "\n",
    "clf_meta_grid_sgd = {\n",
    "  \"loss\": Categorical(['log', 'huber', 'modified_huber']),\n",
    "  \"penalty\": Categorical(['l1', 'l2', 'elasticnet']),\n",
    "  \"l1_ratio\": Real(0.0001, 1, prior='log-uniform'),\n",
    "  \"alpha\": Real(0.00001, 100, prior='log-uniform'),\n",
    "  \"class_weight\": Categorical([None, 'balanced']),\n",
    "  #'learning_rate': Categorical(['constant', 'optimal', 'invscaling']),\n",
    "  #'eta0': Integer(0.1, 1),\n",
    "  'max_iter': Integer(5, 1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_sgd = BayesSearchCV(clf_meta_sgd, search_spaces=clf_meta_grid_sgd, cv=5, n_jobs=-1, \n",
    "                                verbose=3, scoring='roc_auc', n_iter=20, random_state=42)\n",
    "gridcv_meta_sgd.fit(X_train_meta, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gridcv_meta_sgd, '{}/{}{}.pkl'.format(stacking_models_dir, 'meta_2_', 'sgd_without_domainfeatures'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_logreg = LogisticRegression()\n",
    "clf_meta_grid_logreg = [\n",
    "  {\n",
    "    'C': [10, 100, 1000],\n",
    "    'tol': [0.0004, 0.003, 0.002, 0.1],\n",
    "    'class_weight' : [None, 'balanced'],\n",
    "    'random_state': [42],\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_logreg = GridSearchCV(clf_meta_logreg, clf_meta_grid_logreg, cv=5, n_jobs=-1, verbose=3, scoring='roc_auc')\n",
    "gridcv_meta_logreg.fit(X_train_meta, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gridcv_meta_sgd, '{}/{}{}.pkl'.format(stacking_models_dir, 'meta_2_', 'logreg_with_domainfeatures'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_svc = SVC()\n",
    "clf_meta_grid_svc = [\n",
    "  {\n",
    "    'C': [0.0001, 0.1, 1],\n",
    "    'kernel': ['linear'],\n",
    "#    'gamma': [0.01, 1.0],\n",
    "    'class_weight': ['balanced'],\n",
    "    'random_state': [42],\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_svc = GridSearchCV(clf_meta_svc, clf_meta_grid_svc, cv=5, n_jobs=5, verbose=3, scoring='roc_auc')\n",
    "gridcv_meta_svc.fit(X_train_meta, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf_meta_xgb = XGBClassifier()\n",
    "\n",
    "#clf_meta_grid_xgb = {\n",
    "#  \"n_estimators\": [25, 100, 250, 300],\n",
    "#  \"max_depth\": [4, 8 , 16],\n",
    "#  \"num_leaves\": [15, 30]\n",
    "#  \"min_child_weight\": [4, 8],\n",
    "#  \"subsample\": [0.2, 0.8],\n",
    "#  \"learning_rate\": [0.01],\n",
    "#  \"colsample_bytree\": [0.8, 0.6],\n",
    "#  \"objective\": ['binary:logistic'],\n",
    "#  \"random_state\": [42]\n",
    "#}\n",
    "\n",
    "# best params\n",
    "clf_meta_grid_xgb = {\n",
    "  \"n_estimators\": [200, 300],\n",
    "  \"max_depth\": [4],\n",
    "  \"min_child_weight\": [8],\n",
    "  \"subsample\": [0.2],\n",
    "  \"learning_rate\": [0.01],\n",
    "  \"colsample_bytree\": [0.8],\n",
    "  \"objective\": ['binary:logistic'],\n",
    "  \"random_state\": [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_gdb = GridSearchCV(clf_meta_xgb, param_grid=clf_meta_grid_xgb, cv=5, n_jobs=-1, verbose=5, scoring='roc_auc')\n",
    "gridcv_meta_gdb.fit(X_train_meta, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_gdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf_meta_xgb = XGBClassifier(objective='binary:logistic', eval_metric='auc')\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "  clf_meta_xgb, \n",
    "  search_spaces=\n",
    "  {\n",
    "    \"n_estimators\": Integer(50, 300),\n",
    "    \"max_depth\": Integer(1, 50),\n",
    "    \"min_child_weight\": Integer(1, 100),\n",
    "    \"subsample\": Real(0.1, 0.9, prior='log-uniform'),\n",
    "    \"learning_rate\": Real(0.001, 0.1, prior='log-uniform'),\n",
    "    \"colsample_bytree\": Real(0.1, 0.9, prior='log-uniform')\n",
    "  },\n",
    "  n_iter=20,\n",
    "  random_state=42,\n",
    "  verbose=3,\n",
    "  scoring = 'roc_auc',\n",
    "  cv=5,\n",
    "  n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train_meta, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_lgm = LGBMClassifier()\n",
    "\n",
    "clf_meta_grid_lgm = {\n",
    "  'n_estimators': [250, 280, 290, 300],\n",
    "  'learning_rate': [0.02, 0.001],\n",
    "  'num_leaves': [25, 30],\n",
    "  'max_depth': [16, 20, 25],\n",
    "  'random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_lgm = GridSearchCV(clf_meta_lgm, param_grid=clf_meta_grid_lgm, cv=5, n_jobs=-1, verbose=5, scoring='roc_auc')\n",
    "gridcv_meta_lgm.fit(X_train_meta, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_lgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiLayer-Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_meta_mlp = MLPClassifier()\n",
    "\n",
    "clf_meta_grid_mlp = {\n",
    "  #'hidden_layer_sizes': Categorical([(8,5)]),\n",
    "  'hidden_layer_sizes': Categorical([(3,), (5,), (10,), (8,2)]),\n",
    "  'activation': Categorical(['relu', 'logistic', 'tanh']),\n",
    "  'epsilon': Real(1e-9, 1e-4, prior='log-uniform'),\n",
    "  'alpha': Real(0.000000001, 2, prior='log-uniform'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv_meta_mlp = BayesSearchCV(clf_meta_mlp, search_spaces=clf_meta_grid_mlp, cv=5, n_jobs=-1, \n",
    "                                verbose=5, random_state=49, scoring='roc_auc', n_iter=70)\n",
    "gridcv_meta_mlp.fit(X_train_meta, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(gridcv_meta_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gridcv_meta_mlp, '{}/{}{}.pkl'.format(stacking_models_dir, 'meta_2_', 'mlp_without_domainfeatures'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average L1-Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_l1_learners(l1_learners, Xtest):\n",
    "  X_test_l1 = pd.DataFrame()\n",
    "  # make prediction with L1-Learners\n",
    "  for learner in l1_learners:\n",
    "    X_test_l1[learner.unique_name] = learner.clf.predict_proba(Xtest)[:, 1]\n",
    "    \n",
    "  return np.mean(X_test_l1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = average_l1_learners(l1_learners, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the submission dataframe\n",
    "submission = pd.DataFrame({'SK_ID_CURR': X_test_SK_IDS, 'TARGET': y_test})\n",
    "submission.to_csv('average_stacking_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediciton for train set and submit csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(l1_learners, meta_clf, Xtest, extra_features, scaler_meta):\n",
    "  x_test_l1 = pd.DataFrame()\n",
    "  \n",
    "  # make prediction with L1-Learners\n",
    "  for learner in l1_learners:\n",
    "    x_test_l1[learner.unique_name] = learner.clf.predict_proba(Xtest)[:, 1]\n",
    "    \n",
    "  # Add extra features\n",
    "  if len(extra_features) > 0:\n",
    "    columns = prep_train.columns[2:]\n",
    "    for col in extra_features:\n",
    "      # get index of the column\n",
    "      idx = np.where(prep_train.columns[2:].values == col)[0][0]\n",
    "      x_test_l1[col] = Xtest[:,idx]\n",
    "  \n",
    "  if scaler_meta:\n",
    "    # save column names\n",
    "    columns = x_test_l1.columns    \n",
    "    # scale \n",
    "    x_test_l1 = pd.DataFrame(scaler_meta.transform(x_test_l1), columns=columns)\n",
    "  \n",
    "  # make prediction with Meta Learner\n",
    "  return meta_clf.predict_proba(x_test_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_clf = gridcv_meta_logreg.best_estimator_\n",
    "#meta_clf = gridcv_meta_gdb.best_estimator_\n",
    "#meta_clf = gridcv_meta_lgm.best_estimator_\n",
    "#meta_clf = opt.best_estimator_\n",
    "#meta_clf = gridcv_meta_sgd.best_estimator_\n",
    "meta_clf = gridcv_meta_mlp.best_estimator_\n",
    "\n",
    "y_test = make_prediction(l1_learners, meta_clf, X_test, extra_features, scaler_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear stretch of predictions to [0,1]\n",
    "y_test_str = y_test[:, 1]\n",
    "y_test_str = (y_test_str - y_test_str.min()) / (y_test_str.max() - y_test_str.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the submission dataframe\n",
    "submission = pd.DataFrame({'SK_ID_CURR': X_test_SK_IDS, 'TARGET': y_test[:,1]})\n",
    "#submission = pd.DataFrame({'SK_ID_CURR': X_test_SK_IDS, 'TARGET': y_test_str})\n",
    "submission.to_csv('./stacking_submissions/meta_paper/meta_2_mlp.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Grids \n",
    "gridcv_meta_sgd___ = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_2_sgd_without_domainfeatures'))\n",
    "gridcv_meta_sgd_df = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_2_sgd_with_domainfeatures'))\n",
    "\n",
    "gridcv_meta_logreg___ = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_2_logreg_without_domainfeatures'))\n",
    "gridcv_meta_logreg_df = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_2_logreg_with_domainfeatures'))\n",
    "\n",
    "gridcv_meta_mlp___ = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_2_mlp_without_domainfeatures'))\n",
    "gridcv_meta_mlp_df = joblib.load(\"{}/{}.pkl\".format(stacking_models_dir, 'meta_2_mlp_with_domainfeatures'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD (no domain features)\n",
    "#sgd_scores_no_domain = cross_val_predict(gridcv_meta_sgd___.best_estimator_, X_train_meta, y_pred_base, cv=5, n_jobs=-1, method='predict_proba')\n",
    "sgd_scores_with_domain = cross_val_predict(gridcv_meta_sgd_df.best_estimator_, X_train_meta, y_pred_base, cv=5, n_jobs=-1, method='predict_proba')\n",
    "\n",
    "#logreg_scores_no_domain = cross_val_predict(gridcv_meta_logreg___.best_estimator_, X_train_meta, y_pred_base, cv=5, n_jobs=-1, method='predict_proba')\n",
    "#logreg_scores_with_domain = cross_val_predict(gridcv_meta_logreg_df.best_estimator_, X_train_meta, y_pred_base, cv=5, n_jobs=-1, method='predict_proba')\n",
    "\n",
    "#mlp_scores_no_domain = cross_val_predict(gridcv_meta_mlp___.best_estimator_, X_train_meta, y_pred_base, cv=5, n_jobs=-1, method='predict_proba')\n",
    "#mlp_scores_with_domain = cross_val_predict(gridcv_meta_mlp_df.best_estimator_, X_train_meta, y_pred_base, cv=5, n_jobs=-1, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD (no domain)\n",
    "fpr, tpr, threshold = roc_curve(y_pred_base, sgd_scores_no_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='SGD (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.74842, 0.75080))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_pred_base, sgd_scores_with_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='SGD with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75192, 0.75125))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_pred_base, logreg_scores_no_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='LogReg (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.74802, 0.75065))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_pred_base, logreg_scores_with_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='LogReg with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75007, 0.74938))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_pred_base, mlp_scores_no_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='MLP (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75456, 0.75693))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_pred_base, mlp_scores_with_domain[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='MLP with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (roc_auc, 0.75518, 0.75633))\n",
    "\n",
    "plt.grid()\n",
    "plt.title('ROC Meta-Learners with Stacking (Method A)', fontsize=14)\n",
    "plt.xlabel('False positive rate', fontsize=14)\n",
    "plt.ylabel('True positive rate', fontsize=14)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 14})\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
