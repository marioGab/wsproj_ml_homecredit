{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Home Credit Default Risk - Classical Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from six.moves import cPickle as pickle\n",
    "from sklearn.externals import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../data/pickles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with engineered features\n",
    "prep_train = pickle.load(open(os.path.join(data_path, \"prep_train_FE.pkl\"), \"rb\"))\n",
    "prep_test = pickle.load(open(os.path.join(data_path, \"prep_test_FE.pkl\"), \"rb\"))\n",
    "# without engineered features WOEF\n",
    "# prep_train = pickle.load(open(os.path.join(data_path, \"prep_train.pkl\"), \"rb\"))\n",
    "# prep_test = pickle.load(open(os.path.join(data_path, \"prep_test.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307504, 169)\n",
      "(48744, 168)\n"
     ]
    }
   ],
   "source": [
    "print(prep_train.shape)\n",
    "print(prep_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "def plot_roc_curve(y_groundtruth, y_predicted_proba, caption=None, legend=None, lable=None):\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score\n",
    "    fpr, tpr, thresholds = roc_curve(y_groundtruth, y_predicted_proba)\n",
    "    auc = roc_auc_score(y_truth.values.ravel(), y_predicted_proba)\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=legend)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.grid()\n",
    "    plt.title(caption)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_with_auc(y_train, y_train_predicted):\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_train.values.ravel(), y_train_predicted[:,:1])\n",
    "    auc = roc_auc_score(y_train.values.ravel(), y_train_predicted[:,:1])\n",
    "    return fpr, tpr, thresholds, auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission \n",
    "def make_submission(y_test_predicted, sub_file_name):\n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': X_test_SK_IDS, 'TARGET': y_test_predicted[:,1]})\n",
    "    submission.to_csv('./single_ml/submissions/' + sub_file_name + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SK_IDS = prep_train.SK_ID_CURR\n",
    "X_train = prep_train.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "y_train = prep_train.TARGET\n",
    "\n",
    "# delete\n",
    "X_test_SK_IDS = prep_test.SK_ID_CURR\n",
    "X_test = prep_test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "del prep_train\n",
    "del prep_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = std_scaler.transform(X_train)\n",
    "X_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=20)\n",
    "#pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pca.transform(X_train)\n",
    "#X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_reg = LogisticRegression()\n",
    "\n",
    "#param_logreg = {\n",
    "#  \"C\": [0.01, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4],\n",
    "#  \"class_weight\" : ['balanced'],\n",
    "#  \"random_state\" : [42]\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_logreg = GridSearchCV(log_reg, param_grid=param_logreg, cv=5, n_jobs=3, verbose=5, scoring='roc_auc')\n",
    "#grid_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Best Score: {}\".format(grid_logreg.best_score_))\n",
    "#print(\"Best Params: {}\".format(grid_logreg.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#clf_rf = RandomForestClassifier()\n",
    "\n",
    "#param_rf = {\n",
    "#  \"n_estimators\": [100, 150],\n",
    "#  \"max_depth\": [25, 50],\n",
    "#  \"random_state\": [42]\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_rf = GridSearchCV(clf_rf, param_grid=param_rf, cv=5, n_jobs=3, verbose=5, scoring='roc_auc')\n",
    "#grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Best Score: {}\".format(grid_rf.best_score_))\n",
    "#print(\"Best Params: {}\".format(grid_rf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import ElasticNet\n",
    "#clf_eln = ElasticNet()\n",
    "\n",
    "#param_eln = {\n",
    "#  'alpha': [0.001, 0.01, 0.1 , 1, 10],\n",
    "#  'l1_ratio': [0.1, 0.2, 0.3, 0.5, 0.7],\n",
    "#  'random_state': [42]\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_eln = GridSearchCV(clf_eln, param_grid=param_eln, cv=5, n_jobs=-1, verbose=5, scoring='roc_auc')\n",
    "#grid_eln.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Best Score: {}\".format(grid_eln.best_score_))\n",
    "#print(\"Best Params: {}\".format(grid_eln.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neural_network import MLPClassifier\n",
    "#from skopt import BayesSearchCV\n",
    "#from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_meta_mlp = MLPClassifier()\n",
    "\n",
    "#clf_meta_grid_mlp = {\n",
    "#  'hidden_layer_sizes': Categorical([(70, 30)]),\n",
    "#  'alpha': Real(0.0000001, 8, prior='log-uniform'),\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridcv_meta_mlp = BayesSearchCV(clf_meta_mlp, search_spaces=clf_meta_grid_mlp, cv=5, n_jobs=-1, \n",
    "#                                verbose=5, random_state=42, scoring='roc_auc', n_iter=10)\n",
    "#gridcv_meta_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Best Score: {}\".format(gridcv_meta_mlp.best_score_))\n",
    "#print(\"Best Params: {}\".format(gridcv_meta_mlp.best_params_))\n",
    "#for mean, std, params in zip(gridcv_meta_mlp.cv_results_['mean_test_score'], gridcv_meta_mlp.cv_results_['std_test_score'], gridcv_meta_mlp.cv_results_['params']):\n",
    "#  print(\"mean: %0.3f std: (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf_xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_xgb = {\n",
    "  \"n_estimators\": [1000],\n",
    "  \"max_depth\": [8],#, 4],\n",
    "  \"min_child_weight\": [4],\n",
    "  \"subsample\": [0.8],\n",
    "  \"learning_rate\": [0.01],\n",
    "  \"colsample_bytree\": [0.8],\n",
    "  \"objective\": ['binary:logistic'],\n",
    "  \"random_state\": [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] colsample_bytree=0.8, learning_rate=0.01, max_depth=8, min_child_weight=4, n_estimators=1000, objective=binary:logistic, random_state=42, subsample=0.8 \n"
     ]
    }
   ],
   "source": [
    "grid_xgb = GridSearchCV(clf_xgb, param_grid=param_xgb, cv=5, n_jobs=1, verbose=5, scoring='roc_auc')\n",
    "grid_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_xgb=cross_val_predict(grid_xgb.best_estimator_, X_train, y_train, cv=5, verbose=2, n_jobs=1, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(grid_xgb, './single_ml/models/grid_xgb.joblib') # WOEF grid_xgb_wofe\n",
    "joblib.dump(predicts_xgb, './single_ml/predictions/predicts_xgb.joblib') # WOEF predicts_xgb_wofe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score: {}\".format(grid_xgb.best_score_))\n",
    "print(\"Best Params: {}\".format(grid_xgb.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_xgb = grid_xgb.best_estimator_.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the submission dataframe\n",
    "make_submission(y_test_xgb,'xgb_submission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "clf_lgbm = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'nthread':[3],\n",
    "    'n_estimators':[10000],#,500],\n",
    "    'learning_rate':[0.02],\n",
    "    'num_leaves':[34],\n",
    "    'colsample_bytree':[0.9497036],\n",
    "    'subsample':[0.8715623],\n",
    "    'max_depth':[8],\n",
    "    'reg_alpha':[0.041545473],\n",
    "    'reg_lambda':[0.0735294],\n",
    "    'min_split_gain':[0.0222415],\n",
    "    'min_child_weight':[39.3259775],\n",
    "    'verbose':[3],\n",
    "    'metric': ['auc']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lgdb = GridSearchCV(clf_lgbm, param_grid=lgbm_params, cv=5, n_jobs=1, verbose=3, scoring='roc_auc')\n",
    "grid_lgdb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_lgbme=cross_val_predict(grid_lgdb.best_estimator_, X_train, y_train, cv=5, verbose=2, n_jobs=1, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(grid_lgdb, './single_ml/models/grid_lgdb.joblib') # WOEF grid_lgdb_wofe\n",
    "joblib.dump(predicts_lgbm, './single_ml/predictions/predicts_lgbm.joblib') # WOEF predicts_lgbm_wofe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score: {}\".format(grid_lgdb.best_score_))\n",
    "print(\"Best Params: {}\".format(grid_lgdb.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_lgbm = grid_lgdb.best_estimator_.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the submission\n",
    "make_submission(y_test_lgbm,'lgbm_submission_gs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only works if you first create the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WOEF\n",
    "#grid_lgdb_wofe = joblib.load('./single_ml/models/grid_lgdb_wofe.joblib')\n",
    "predicts_lgbm_wofe = joblib.load('./single_ml/predictions/predicts_lgbm_wofe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_lgdb = joblib.load('./single_ml/models/grid_lgdb.joblib')\n",
    "predicts_lgbm = joblib.load('./single_ml/predictions/predicts_lgbm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WOEF\n",
    "#grid_xgb_wofe = joblib.load('./single_ml/models/grid_xgb_wofe.joblib')\n",
    "predicts_xgb_wofe = joblib.load('./single_ml/predictions/predicts_xgb_wofe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_xgb = joblib.load('./single_ml/models/grid_xgb.joblib')\n",
    "predicts_xgb = joblib.load('./single_ml/predictions/predicts_xgb.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC for XGBoost and LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(y_train, predicts_xgb[:,1:])\n",
    "auc_xgb = roc_auc_score(y_train.values.ravel(), predicts_xgb[:,1:])\n",
    "\n",
    "fpr_lgbm, tpr_lgbm, thresholds_lgbm = roc_curve(y_train, predicts_lgbm[:,1:])\n",
    "auc_lgbm = roc_auc_score(y_train.values.ravel(), predicts_lgbm[:,1:])\n",
    "\n",
    "fpr_xgb_wofe, tpr_xgb_wofe, thresholds_xgb_wofe = roc_curve(y_train, predicts_xgb_wofe[:,1:])\n",
    "auc_xgb_wofe = roc_auc_score(y_train.values.ravel(), predicts_xgb_wofe[:,1:])\n",
    "\n",
    "fpr_lgbm_wofe, tpr_lgbm_wofe, thresholds_lgbm_wofe = roc_curve(y_train, predicts_lgbm_wofe[:,1:])\n",
    "auc_lgbm_wofe = roc_auc_score(y_train.values.ravel(), predicts_lgbm_wofe[:,1:])\n",
    "\n",
    "caption = 'ROC -XGBoost vs LightGBM (with and without EF)'\n",
    "\n",
    "# Create plots with pre-defined labels.\n",
    "# Alternatively, you can pass labels explicitly when calling `legend`.\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(13.5, 10, forward=True)\n",
    "\n",
    "ax.plot(fpr_xgb, tpr_xgb, 'r:', label='XGBoost with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (round(auc_xgb,5), 0.75977, 0.75930))\n",
    "ax.plot(fpr_xgb_wofe, tpr_xgb_wofe, 'r' ,label='XGBoost (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (round(auc_xgb_wofe,5), 0.74427, 0.74407))\n",
    "ax.plot(fpr_lgbm, fpr_lgbm, 'b:', label='LightGBM with EF (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (round(auc_lgbm,5), 0.74261, 0.74478))\n",
    "ax.plot(fpr_lgbm_wofe, tpr_lgbm_wofe, 'b' ,label='LightGBM (CV=%0.5f, PubLB=%0.5f, PriLB=%0.5f)' % (round(auc_lgbm_wofe,5), 0.73145, 0.73287))\n",
    "\n",
    "# Now add the legend with some customizations.\n",
    "legend = ax.legend(loc='lower right', shadow=True)\n",
    "\n",
    "# The frame is matplotlib.patches.Rectangle instance surrounding the legend.\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.9')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.grid()\n",
    "plt.title(caption, fontsize=14)\n",
    "plt.xlabel('False positive rate', fontsize=14)\n",
    "plt.ylabel('True positive rate', fontsize=14)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 14})\n",
    "\n",
    "fig.savefig('xgb_vs_lgbm.png', dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
